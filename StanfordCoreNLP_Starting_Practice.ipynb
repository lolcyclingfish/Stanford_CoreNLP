{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1\n",
    "\n",
    "http://www.klintonbicknell.com/ling400fall2017/hw/hw1.html\n",
    "\n",
    "#before calling server in python, need to start server in terminal within the directory where Stanford Corenlp sorce folder is located at\n",
    "#source folder: C:\\Users\\Dingding\\stanford-corenlp-full-2017-06-09\n",
    "#command line: java -Xmx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000\n",
    "\n",
    "#ref.:https://stanfordnlp.github.io/CoreNLP/corenlp-server.html\n",
    "#ref.:https://stanfordnlp.github.io/CoreNLP/corenlp-server.html#starting-the-server\n",
    "#ref.:https://github.com/smilli/py-corenlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in classbios.txt as list of sentences \n",
    "# Split sentences by '\\n' or use corenlp's ssplit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('classbios.txt', encoding=\"utf8\") as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "content = [x.split('\\n') for x in content] \n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_file=open('classbios.txt', 'r',encoding=\"utf8\")\n",
    "text_file=text_file.read()\n",
    "#print(text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_split = nlp.annotate(text_file, properties={\n",
    "  'annotators': 'ssplit',\n",
    "  'outputFormat': 'json'\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#text_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#join split tokens into sentences:\n",
    "sentences=[]\n",
    "for s in text_split['sentences']:\n",
    "    sentences.append(' '.join([t['word'] for t in s['tokens']]))\n",
    "#sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expression for Time Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Regex for time expressions:\n",
    "import re\n",
    "\n",
    "time_pattern_list=['((0?[13578]|10|12)(-|\\/)(([1-9])|(0[1-9])|([12])([0-9]?)|(3[01]?))(-|\\/)((19)([2-9])(\\d{1})|(20)([01])(\\d{1})|([8901])(\\d{1}))|(0?[2469]|11)(-|\\/)(([1-9])|(0[1-9])|([12])([0-9]?)|(3[0]?))(-|\\/)((19)([2-9])(\\d{1})|(20)([01])(\\d{1})|([8901])(\\d{1})))',\n",
    "                  #matches M/D/YY, M/D/YYY, MM/DD/YY, MM/DD/YYYY\n",
    "                   '(((1[0-2]|0?[1-9]) ([AaPp][Mm])))|(((1[0-2]|0?[1-9])([AaPp][Mm])))'\n",
    "                   #matches ##pm, ## am, #pm, # am\n",
    "                   '(((1[0-2]|0?[1-9]):([0-5][0-9]) ([AaPp][Mm])))|(((1[0-2]|0?[1-9]):([0-5][0-9])([AaPp][Mm])))'\n",
    "                   #matches ##:##pm, ##:## pm, #:##pm, #:## pm\n",
    "                   '((([1-2][0-9]|0?[1-9]):([0-5][0-9]) (pst|PST|Pacific|cst|CST|Central|est|EST|Estern)))|((([1-2][0-9]|0?[1-9]):([0-5][0-9])(pst|PST|Pacific|cst|CST|Central|est|EST|Estern)))'\n",
    "                   #matches ##:## CST/PST/EST, ##:##CST/PST/EST\n",
    "                   '(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) ([1-3][0-9](th|st|nd)?|0?[1-9](th|st|nd)?)'\n",
    "                   #matches Mmm ##st, Mmm #nd,\n",
    "                   '(January|February|March|April|May|June|July|August|Septempter|Octocber|November|December) ([1-3][0-9](th|st|nd)?|0?[1-9](th|st|nd)?)'\n",
    "                  ]\n",
    "keyphrase_list=['years ago', 'months ago', 'days ago', 'after', 'before', 'spring', 'summer','fall','winter']\n",
    "\n",
    "#extract sentences with time points:\n",
    "time_point_sentences=[]\n",
    "for pattern in time_pattern_list:\n",
    "    for sentence in sentences:\n",
    "        if re.match(pattern, sentence):\n",
    "            time_point_sentences.append(sentence)\n",
    "#There is no contains() on either ascii or uft8 strings, we use find() instead which gives the index position of matched phrase if there is a match, otherwise -1\n",
    "for keyphrase in keyphrase_list:\n",
    "    for sentence in sentences:\n",
    "        if sentence.find(keyphrase)>-1:\n",
    "            time_point_sentences.append(sentence)\n",
    "            \n",
    "#to avoid duplicates, we take the unique set of values from the list above\n",
    "#remember to convert the set object back to list object:\n",
    "time_point_sentences=list(set(time_point_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['While my work at Resolution Economics LLC after graduation , my passion to handle data that is material to everyday life has grown .',\n",
       " \"I came straight out of undergrad before coming to MSiA , and my reasons for doing so were a mixture of continuing my education in an area that was widely applicable and pretty interesting to me and avoiding the `` real working '' world to gain more of a sense of direction .\",\n",
       " 'I came to MSIA after spending two years as a Risk Analyst , helping ecommerce companies with fraud .',\n",
       " \"I attended college , worked and earned a master 's degree in New York City before coming to Northwestern .\",\n",
       " 'I have been investigating machine learning for about two years before I came to MSiA , and my biggest research project attempts to classify the image data of plankton to a specific species .',\n",
       " 'I applied for graduate school right after my bachelors and luckily got accepted into this great program at Northwestern .',\n",
       " 'During my sophomore summer I took a probability theory class and was captivated by the endless possibilities and applications of statistics .',\n",
       " \"In an alternate universe , I 'd probably be studying history ... which I might still do after retirement .\",\n",
       " 'Little did I know how bad the winter was .',\n",
       " 'DataSci exposed me to many topics related to analytics and machine learning that I had never seen before .',\n",
       " 'I graduated summa cum laude from Knox College with a B.A. in Data Analytics and a minor in Economics after three years of study .',\n",
       " 'I started to become interested in text analytics after noticing that many internships and full-time positions were requiring experience in Text Analytics and Natural Language Processing .',\n",
       " 'I became interested in text analytics since I joined the MSiA program , as I have not heard about the term before that .',\n",
       " 'It was challenging and rewarding work , but after a couple years , I felt like I wanted to switch to a less niche and narrow field .',\n",
       " 'I first developed an interest in data science after taking a business statistics course at Duke .',\n",
       " 'I grew up in Walnut Creek before moving around during 8th grade .',\n",
       " \"I do not have a full-time offer yet , but I 'm hoping to return to WeWork or another firm in New York after I graduate .\",\n",
       " 'Text analytics started to become interesting to me over the summer where I worked as a Data Scientist for a political consulting firm .',\n",
       " 'My desire to apply math to make real world business decisions led me to the field of economic consulting after graduation .',\n",
       " 'At my internship this summer at a policy research organization , I learned about an interesting project using text analytics to classify domestic abuse cases in crisis text hotline data .',\n",
       " 'I became interested in text analytics after self-studying the topic and using regular expressions in various projects such as classifying FAQs from prospective applicants to the Northwestern MSIA program and scraping web data by patterns in nested html and json formats .',\n",
       " 'It certainly has its pitfalls as any methodology does , but it showed a lot of promise .',\n",
       " 'Over the summer , I mostly worked on sentiment analysis using the VADER algorithm in the nltk package in python .',\n",
       " \"`` Whatever , '' I 'd think after messing up an experiment or getting a bad grade , `` it 's not like I actually want to go to grad school anyway . ''\",\n",
       " 'This past summer , I worked at Nike on the North America Analytics Team as a Data Science intern .',\n",
       " 'This summer I had the opportunity to play at a beach tournament in Wildwood , New Jersey .',\n",
       " 'As someone who grew up in the heart of the Silicon Valley and has been a part of seemingly every type of organization but , I would love to work with data at a startup immediately after graduation .',\n",
       " \"Realizing that my program was focused on producing academicians , funneling me into a life of low pay and grant revisions , I searched for an industry focused program after receiving my Master 's at ASU .\",\n",
       " 'I attended UCDavis for 2 years before UCLA .',\n",
       " 'Certain classes of assets were deemed more risky or volatile than others ; these assets needed to be flagged for closer inspection before they either left the firm or came into its holdings .',\n",
       " 'Though the only work experience I have is a couple of internships , and no full time experience , I was exposed to some lightweight analytics in my most recent internship the summer before MSiA .',\n",
       " 'I spent this past summer interning in New York for a company called WeWork , which builds co-working spaces for other firms to share .',\n",
       " \"The other time I used LSTM to try to generate text from Wall Street Journal , and it turned out the model could n't generate any meaningful words even after days of training .\",\n",
       " \"This did n't work as well as I 'd hoped , and after several months without a consistent and livable paycheck , I joined a financial software company called Eze Software Group as a technical consultant .\",\n",
       " 'For the immediate future , I have recently accepted a full time position from the company where I interned over the summer .',\n",
       " 'There I learned mathematics and how to catch a falling pinecone .',\n",
       " 'As to why Northwestern , I was visiting friends in Evanston in the summer of 2015 and got to visit Northwestern campus , which I thought was beautiful .',\n",
       " 'This summer I worked at Chatham Financial , a financial advisory company in Kennett Square , Pennsylvania .',\n",
       " 'Text analytics has been an interest of mine since before the program because my mother works in the field .',\n",
       " 'During my senior spring I took a natural language processing class that was taught from a more statistics perspective rather than a computer science perspective .',\n",
       " 'Further , when I was looking at the electives for the fall quarter this year I found text analytics as an option .',\n",
       " \"Ideally , in a location I have n't been before .\",\n",
       " '** HW0 : KEVIN ZHAI ------------------------------------------------------------ Some years ago , my dad was an studying English in college in Nanjing , China .']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time_point_sentences) #17 sentences\n",
    "time_point_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write matched sentences to local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write list of sentences to local txt file with each sentence in a new line\n",
    "output_file = open('classbios_timepoints.txt', 'w')\n",
    "for sentence in time_point_sentences:\n",
    "    output_file.write(\"%s\\n\" % sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
